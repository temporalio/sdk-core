mod bridge;
mod driven_workflow;
mod history_update;
pub(crate) mod workflow_tasks;

pub(crate) use bridge::WorkflowBridge;
pub(crate) use driven_workflow::{DrivenWorkflow, WorkflowFetcher};
pub(crate) use history_update::{HistoryPaginator, HistoryUpdate};

use crate::{
    machines::{ProtoCommand, WFCommand, WFMachinesError, WorkflowMachines},
    telemetry::metrics::MetricsContext,
};
use std::sync::mpsc::Sender;
use temporal_sdk_core_protos::coresdk::workflow_activation::WfActivation;

pub(crate) const LEGACY_QUERY_ID: &str = "legacy_query";
type Result<T, E = WFMachinesError> = std::result::Result<T, E>;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub(crate) enum CommandID {
    Timer(u32),
    Activity(u32),
    ChildWorkflowStart(u32),
    ChildWorkflowComplete(u32),
    SignalExternal(u32),
    CancelExternal(u32),
}

/// Manages an instance of a [WorkflowMachines], which is not thread-safe, as well as other data
/// associated with that specific workflow run.
pub(crate) struct WorkflowManager {
    machines: WorkflowMachines,
    /// Is always `Some` in normal operation. Optional to allow for unit testing with the test
    /// workflow driver, which does not need to complete activations the normal way.
    command_sink: Option<Sender<Vec<WFCommand>>>,
}

impl WorkflowManager {
    /// Create a new workflow manager given workflow history and execution info as would be found
    /// in [PollWorkflowTaskQueueResponse]
    pub fn new(
        history: HistoryUpdate,
        namespace: String,
        workflow_id: String,
        run_id: String,
        metrics: MetricsContext,
    ) -> Self {
        let (wfb, cmd_sink) = WorkflowBridge::new();
        let state_machines = WorkflowMachines::new(
            namespace,
            workflow_id,
            run_id,
            history,
            Box::new(wfb).into(),
            metrics,
        );
        Self {
            machines: state_machines,
            command_sink: Some(cmd_sink),
        }
    }

    #[cfg(test)]
    pub fn new_from_machines(workflow_machines: WorkflowMachines) -> Self {
        Self {
            machines: workflow_machines,
            command_sink: None,
        }
    }
}

#[derive(Debug)]
pub struct OutgoingServerCommands {
    pub commands: Vec<ProtoCommand>,
    pub replaying: bool,
}

impl WorkflowManager {
    /// Given history that was just obtained from the server, pipe it into this workflow's machines.
    ///
    /// Should only be called when a workflow has caught up on replay (or is just beginning). It
    /// will return a workflow activation if one is needed.
    pub async fn feed_history_from_server(
        &mut self,
        update: HistoryUpdate,
    ) -> Result<WfActivation> {
        self.machines.new_history_from_server(update).await?;
        self.get_next_activation().await
    }

    /// Fetch the next workflow activation for this workflow if one is required. Doing so will apply
    /// the next unapplied workflow task if such a sequence exists in history we already know about.
    ///
    /// Callers may also need to call [get_server_commands] after this to issue any pending commands
    /// to the server.
    pub async fn get_next_activation(&mut self) -> Result<WfActivation> {
        // First check if there are already some pending jobs, which can be a result of replay.
        let activation = self.machines.get_wf_activation();
        if !activation.jobs.is_empty() {
            return Ok(activation);
        }

        self.machines.apply_next_wft_from_history().await?;
        Ok(self.machines.get_wf_activation())
    }

    /// Typically called after [get_next_activation], use this to retrieve commands to be sent to
    /// the server which been generated by the machines since it was last called.
    pub fn get_server_commands(&self) -> OutgoingServerCommands {
        OutgoingServerCommands {
            commands: self.machines.get_commands(),
            replaying: self.machines.replaying,
        }
    }

    /// Feed the workflow machines new commands issued by the executing workflow code, and iterate
    /// the machines.
    pub async fn push_commands(&mut self, cmds: Vec<WFCommand>) -> Result<()> {
        if let Some(cs) = self.command_sink.as_mut() {
            cs.send(cmds).map_err(|_| {
                WFMachinesError::Fatal("Internal error buffering workflow commands".to_string())
            })?;
        }
        self.machines.iterate_machines().await?;
        Ok(())
    }
}

/// Determines when workflows are kept in the cache or evicted
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub(crate) enum WorkflowCachingPolicy {
    /// Workflows are cached until evicted explicitly or the cache size limit is reached, in which
    /// case they are evicted by least-recently-used ordering.
    Sticky {
        /// The maximum number of workflows that will be kept in the cache
        max_cached_workflows: usize,
    },
    /// Workflows are evicted after each workflow task completion. Note that this is *not* after
    /// each workflow activation - there are often multiple activations per workflow task.
    NonSticky,

    /// Not a real mode, but good for imitating crashes. Evict workflows after *every* reply,
    /// even if there are pending activations
    #[cfg(test)]
    AfterEveryReply,
}

#[cfg(test)]
pub mod managed_wf {
    use super::*;
    use crate::{
        machines::WFCommand,
        prototype_rust_sdk::{WorkflowFunction, WorkflowResult},
        test_help::{TestHistoryBuilder, TEST_Q},
        workflow::WorkflowFetcher,
    };
    use std::convert::TryInto;
    use temporal_sdk_core_protos::coresdk::{
        common::Payload,
        workflow_activation::create_evict_activation,
        workflow_completion::{wf_activation_completion::Status, WfActivationCompletion},
    };
    use tokio::{
        sync::mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
        task::JoinHandle,
    };

    pub(crate) struct WFFutureDriver {
        completions_rx: UnboundedReceiver<WfActivationCompletion>,
    }

    #[async_trait::async_trait]
    impl WorkflowFetcher for WFFutureDriver {
        async fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand> {
            if let Some(completion) = self.completions_rx.recv().await {
                completion
                    .status
                    .map(|s| match s {
                        Status::Successful(s) => s
                            .commands
                            .into_iter()
                            .map(|cmd| cmd.try_into().unwrap())
                            .collect(),
                        Status::Failed(_) => panic!("Ahh failed"),
                    })
                    .unwrap_or_default()
            } else {
                // Sender went away so nothing to do here. End of wf/test.
                vec![]
            }
        }
    }

    #[must_use]
    pub struct ManagedWFFunc {
        mgr: WorkflowManager,
        activation_tx: UnboundedSender<WfActivation>,
        future_handle: Option<JoinHandle<WorkflowResult<()>>>,
        was_shutdown: bool,
    }

    impl ManagedWFFunc {
        pub fn new(hist: TestHistoryBuilder, func: WorkflowFunction, args: Vec<Payload>) -> Self {
            Self::new_from_update(hist.as_history_update(), func, args)
        }

        pub fn new_from_update(
            hist: HistoryUpdate,
            func: WorkflowFunction,
            args: Vec<Payload>,
        ) -> Self {
            let (completions_tx, completions_rx) = unbounded_channel();
            let (wff, activations) = func.start_workflow(
                "testnamespace".to_string(),
                TEST_Q.to_string(),
                args,
                completions_tx,
            );
            let spawned = tokio::spawn(wff);
            let driver = WFFutureDriver { completions_rx };
            let state_machines = WorkflowMachines::new(
                "test_namespace".to_string(),
                "wfid".to_string(),
                "runid".to_string(),
                hist,
                Box::new(driver).into(),
                Default::default(),
            );
            let mgr = WorkflowManager::new_from_machines(state_machines);
            Self {
                mgr,
                activation_tx: activations,
                future_handle: Some(spawned),
                was_shutdown: false,
            }
        }

        pub(crate) async fn get_next_activation(&mut self) -> Result<WfActivation> {
            let res = self.mgr.get_next_activation().await?;
            debug!("Managed wf next activation: {}", &res);
            if res.jobs.is_empty() {
                // Nothing to do here
                return Ok(res);
            }
            self.push_activation_to_wf(res.clone()).await?;
            Ok(res)
        }

        /// Return outgoing server commands as of the last iteration
        pub(crate) async fn get_server_commands(&mut self) -> OutgoingServerCommands {
            self.mgr.get_server_commands()
        }

        /// Feed new history, as if received a new poll result. Returns new activation
        pub(crate) async fn new_history(&mut self, update: HistoryUpdate) -> Result<WfActivation> {
            let res = self.mgr.feed_history_from_server(update).await?;
            self.push_activation_to_wf(res.clone()).await?;
            Ok(res)
        }

        /// During testing it can be useful to run through all activations to simulate replay
        /// easily. Returns the last produced activation with jobs in it, or an activation with no
        /// jobs if the first call had no jobs.
        pub(crate) async fn process_all_activations(&mut self) -> Result<WfActivation> {
            let mut last_act = self.get_next_activation().await?;
            let mut next_act = self.get_next_activation().await?;
            while !next_act.jobs.is_empty() {
                last_act = next_act;
                next_act = self.get_next_activation().await?;
            }
            Ok(last_act)
        }

        pub async fn shutdown(&mut self) -> WorkflowResult<()> {
            self.was_shutdown = true;
            // Send an eviction to ensure wf exits if it has not finished (ex: feeding partial hist)
            let _ = self.activation_tx.send(create_evict_activation(
                "not actually important".to_string(),
                "force shutdown".to_string(),
            ));
            self.future_handle.take().unwrap().await.unwrap()
        }

        async fn push_activation_to_wf(&mut self, res: WfActivation) -> Result<()> {
            self.activation_tx
                .send(res)
                .expect("Workflow should not be dropped if we are still sending activations");
            self.mgr.machines.iterate_machines().await?;
            Ok(())
        }
    }

    impl Drop for ManagedWFFunc {
        fn drop(&mut self) {
            // Double panics cause a SIGILL
            if !self.was_shutdown && !std::thread::panicking() {
                panic!("You must call `shutdown` to properly use ManagedWFFunc in tests")
            }
        }
    }
}
